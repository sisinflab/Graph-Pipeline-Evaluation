experiment:
  backend: pytorch
  data_config:
    strategy: fixed
    train_path: ../data/{0}/train.tsv
    test_path: ../data/{0}/test.tsv
  dataset: dataset_name
  top_k: 20
  evaluation:
    cutoffs: [20]
    simple_metrics: [Recall, nDCG, Precision]
  gpu: -1
  external_models_path: ../external/models/__init__.py
  models:
#    external.NGCF:
#      meta:
#        hyper_opt_alg: grid
#        verbose: True
#        save_weights: False
#        validation_rate: 10
#        validation_metric: Recall@20
#        restore: False
#        write_best_iterations: True
#      lr: 0.0001
#      epochs: 400
#      factors: 64
#      batch_size: 1024
#      l_w: 1e-5
#      n_layers: 3
#      weight_size: 64
#      node_dropout: 0.1
#      message_dropout: 0.1
#      normalize: True
#      seed: 42
#      early_stopping:
#        patience: 5
#        mode: auto
#        monitor: Recall@20
#        verbose: True
    external.LightGCN:
      meta:
        hyper_opt_alg: grid
        verbose: True
        save_weights: False
        validation_rate: 20
        validation_metric: Recall@20
        restore: False
        write_best_iterations: True
      lr: 0.001
      epochs: 1000
      factors: 64
      batch_size: 2048
      l_w: 1e-4
      n_layers: 3
      normalize: True
      seed: 42
      early_stopping:
        patience: 5
        mode: auto
        monitor: Recall@20
        verbose: True
#    # 8
#    external.DGCF:
#      meta:
#        hyper_opt_alg: grid
#        verbose: True
#        save_weights: False
#        validation_rate: 1
#        validation_metric: Recall@20
#        restore: False
#        write_best_iterations: True
#      lr: 0.001
#      epochs: 1000
#      factors: 64
#      batch_size: 1024
#      l_w_bpr: [0.001, 0.00001]
#      l_w_ind: [0.001, 0.00001]
#      ind_batch_size: 1024
#      n_layers: [1, 2, 3, 4]
#      routing_iterations: 2
#      intents: [2, 4, 8, 16]
#      seed: 123
#      early_stopping:
#        patience: 50
#        mode: auto
#        monitor: Recall@20
#        verbose: True
#    # 64
#    external.LRGCCF:
#      meta:
#        hyper_opt_alg: grid
#        verbose: True
#        save_weights: False
#        validation_rate: 1
#        validation_metric: Recall@20
#        restore: False
#        write_best_iterations: True
#      lr: 0.001
#      epochs: 1000
#      factors: 64
#      batch_size: 1024
#      l_w: 0.01
#      n_layers: [1, 2, 3, 4]
#      normalize: [True, False]
#      seed: 123
#      num_neg: 1
#      early_stopping:
#        patience: 50
#        mode: auto
#        monitor: Recall@20
#        verbose: True
    # 8
#    external.SGL:
#      meta:
#        hyper_opt_alg: grid
#        verbose: True
#        save_weights: False
#        validation_rate: 1
#        validation_metric: Recall@20
#        restore: False
#        write_best_iterations: True
#      lr: 0.001
#      epochs: 1000
#      batch_size: 1024
#      factors: 64
#      l_w: 1e-4
#      n_layers: 4
#      ssl_temp: 1
#      ssl_reg: 0.005
#      ssl_ratio: 0.5
#      sampling: nd
#      early_stopping:
#        patience: 50
#        mode: auto
#        monitor: Recall@20
#        verbose: True
    # 96
#    external.UltraGCN:
#      meta:
#        hyper_opt_alg: grid
#        verbose: True
#        save_weights: False
#        validation_rate: 1
#        validation_metric: Recall@20
#        restore: False
#        write_best_iterations: True
#      lr: 1e-4
#      epochs: 2000
#      factors: 64
#      batch_size: 512
#      g: 1e-4
#      l: 5e-4
#      w1: 1e-6
#      w2: 1.0
#      w3: 1e-6
#      w4: 1.0
#      ii_n_n: 10
#      n_n: 1500
#      n_w: 300
#      s_s_p: False
#      i_w: 0.0001
#      seed: 123
#      early_stopping:
#        patience: 50
#        mode: auto
#        monitor: Recall@20
#        verbose: True
#    # 40
#    external.SVDGCN:
#      meta:
#        hyper_opt_alg: grid
#        verbose: True
#        save_weights: False
#        validation_rate: 1
#        validation_metric: Recall@20
#        restore: False
#        write_best_iterations: True
#      factors: 64
#      epochs: 15
#      batch_size: 1024
#      l_w: 0.01
#      lr: 7.0
#      req_vec: [60, 90]
#      beta: 2.0
#      alpha: [2.0, 3.0]
#      coef_u: [0.1, 0.3, 0.5, 0.7]
#      coef_i: [0.1, 0.3, 0.5, 0.7]
#      seed: 123
    # 64
    # no early stopping because epochs are very low